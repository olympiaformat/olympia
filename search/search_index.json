{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Olympia Format","text":"<p>Olympia is a storage-only Open Catalog Format for big data analytics, ML &amp; AI.  It defines a file spec and layout on storage to store and access metadata  for commonly used objects in a data lakehouse catalog like Apache Iceberg tables, Substrait views, etc.</p> <p>Olympia is designed for the following key use cases and features:</p>"},{"location":"#scalable-lightweight-and-portable-storage-only-lakehouse-catalog","title":"Scalable, Lightweight and Portable Storage-Only Lakehouse Catalog","text":"<p>If you would like a lightweight lakehouse catalog that can scale to millions or even billions of objects without the need to run a server or use a vendor catalog integration, Olympia is the perfect solution for you.</p> <p>Olympia only relies on one storage primitive - mutual exclusion of file creation, which is available in almost all storage solutions including Linux file system, Apache HDFS, Amazon S3, Google Cloud Storage, Azure Data Lake Storage, etc. Olympia as a format also uses relative paths across the board,  so that you can easily port your Olympia catalog from one storage to another by simply copying all the contents a directory.</p>"},{"location":"#embedded-component-for-communication-protocol-servers","title":"Embedded Component for Communication Protocol Servers","text":"<p>If you would like to build a server that is compliant with  open or proprietary communication protocols like the Apache Iceberg REST catalog standard, you can use Olympia to handle all the technical complexities of interacting with different types of objects in a catalog, and put your focus on developing business logic in your catalog server such as authentication,  server routing, server monitoring, etc.</p>"},{"location":"#multi-object-multi-statement-transactions","title":"Multi-Object Multi-Statement Transactions","text":"<p>Olympia enables multi-object multi-statement transactions across all objects managed by the catalog. You can easily perform operations like atomically committing multiple tables,  atomically refreshing a view after updating a table while ensuring  SNAPSHOT or SERIALIZABLE isolation level across the entire lakehouse. We also provide commonly seen transaction SQL extensions like <code>BEGIN TRANSACTION</code>, <code>COMMIT TRANSACTION</code>, <code>ROLLBACK TRANSACTION</code> in open engines like Apache Spark.</p>"},{"location":"#consistent-time-travel-rollback-and-snapshot-export","title":"Consistent Time Travel, Rollback and Snapshot Export","text":"<p>Every time a new change happens in an Olympia catalog, a new version of the catalog is created. This means the whole catalog is versioned and can support time travel and version travel. Compared to single table time travel feature provided by open table formats,  Olympia time travel ensures that all objects in a catalog are in the specific point in time, avoiding data errors created by inconsistent states across different tables. In addition, you can roll back an entire catalog to a specific previous state, or export everything in a catalog at a point of time as a snapshot.</p>"},{"location":"#distributed-transactions","title":"Distributed Transactions","text":"<p>Olympia enables advanced transaction semantics like distributed transaction  that is had been only available in relational database products like Microsoft SQL Server. When beginning a distributed transaction in an Olympia catalog, the transaction can be passed around different processes across any supported compute engines. This is useful for write-audit-publish workloads where a writer can pass a transaction to an auditor for review, and eventually be committed into the catalog through a publisher. Compared to similar write-audit-publish features provided at table format level, Olympia allows arbitrary operations against any number and any type of object  to be processed in the workflow atomically.</p>"},{"location":"community/","title":"Community","text":"<p>Olympia is a young project at early development stage. If you are interested in helping, feel free to join our discussions and contribute to our codebase!</p>"},{"location":"community/#slack","title":"Slack","text":"<p>we mainly use Slack (click for invite link) for day-to-day communications and quick conversations.</p>"},{"location":"community/#github","title":"GitHub","text":"<p>We mainly use GitHub Discussions and GitHub Issues to track long-lasting discussions. You can check good first issues to get started with contributing. For developer setup, you can check the project README for more details.</p>"},{"location":"format/","title":"Format","text":"<p>This page describes the complete Olympia catalog format on storage.</p>"},{"location":"format/#overview","title":"Overview","text":"<p>The Olympia format defines a set of files that are within a specific prefix. These files together forms a b-tree that records the information of objects in a catalog. Here is an example:</p> <p></p> <p>The graph above describes an Olympia catalog at storage location <code>/prefix</code>. The catalog is at version 100 with 1 root node and 3 child nodes forming a b-tree of order 4. Each node of the b-tree is serialized as a file within the prefix.  The root node is at location <code>/prefix/vn/00100110000000000000000000000000</code>, and 3 child nodes at locations within <code>/prefix/node/</code>.</p> <p>The b-tree is used as a key-value map, where the key encodes the object name, and the value is a location within prefix that has the definition of the object as a serialized protobuf file. For example, in this catalog there are object keys like <code>catalog_def</code>, <code>ns1</code>, <code>ns2.table2</code>, etc. with their corresponding definitions as files at locations within <code>/prefix/def/</code>.</p>"},{"location":"format/#b-tree-concepts","title":"B-Tree Concepts","text":""},{"location":"format/#search-tree","title":"Search Tree","text":"<p>A search tree is a tree data structure used for locating specific Keys from within a collection of keys, and used as an implementation of a Set.  A search tree consists of a collection of Nodes, and each node contains an ordered collection of keys. To find if a target key is in the tree set, run the following algorithm:</p> <p>Start from the root node, we first check see if the target is in the node. If not, find the 2 consecutive keys that bound the target, or if the target is smaller or larger than all keys in the node. This will either lead to searching a subsequent child node and eventually find the target in the set, or if there is no child node to search, the key is not in the set.</p>"},{"location":"format/#n-way-search-tree","title":"N-Way Search Tree","text":"<p>A N-way search tree is a search tree where:</p> <ol> <li>A node with <code>k</code> children must have <code>k-1</code> number of keys.</li> <li>Each node must have a maximum of <code>N</code> child nodes (i.e. each node must have a maximum of <code>N-1</code> keys)</li> </ol>"},{"location":"format/#search-tree-map","title":"Search Tree Map","text":"<p>A search tree can not only be used as the implementation of a set, but also a key-value Map. This can be achieved by storing the value together with its corresponding key.</p> <p>When we talk about a tree in the context of Olympia, it is always a search tree map. It is also common for a value in the map to be pointers to a much larger payload on disk.</p>"},{"location":"format/#b-tree","title":"B-Tree","text":"<p>An N-way search tree only enforces the general requirements for the number of children per tree node. The tree could become imbalanced over time.  A b-tree (balanced tree) of order N is a self-balancing N-way search tree that enforces a set of rules when updating the tree:</p> <ol> <li>All leaf nodes must appear at the same level</li> <li>The root node must have at least 2 children, unless it is also a leaf</li> <li>All nodes, except for the root node and leaves, must have at least <code>\u2308N/2\u2309</code> children</li> </ol>"},{"location":"format/#pivot-table","title":"Pivot Table","text":"<p>For each node of a b-tree, there is an internal mapping of key to value and child node pointers. A Pivot Table provides a way to describe such information in a tabular fashion.</p> <p>Every key, value and node pointer tuple forms a row in this pivot table. There are exactly <code>N</code> rows for each node in a <code>N</code>-way search tree. The construction of the table follows the rules below:</p> <ol> <li>The first row must have <code>NULL</code> key and <code>NULL</code> value, and the node pointer (if exists) points to the leftest child node.</li> <li>Subsequent rows must be filled with non-null key and value from left to right.    The node pointer at the row (if exists) points to the right child node of the key at the same row.</li> <li>If there are less than <code>N-1</code> keys available to form <code>N</code> rows, the remaining rows are filled with all <code>NULL</code> values for key,    value and node pointer.</li> </ol> <p>For example, the pivot table of the root node in the example in overview would look something like:</p> Key Value Node Pointer NULL NULL node/&lt;some random value&gt;.arrow ns1 def/&lt;some random value&gt;.binpb node/&lt;some random value&gt;.arrow ns2 def/&lt;some random value&gt;.binpb node/&lt;some random value&gt;.arrow"},{"location":"format/#catalog-objects-and-actions","title":"Catalog Objects and Actions","text":"<p>Each type of object in a catalog has a Protobuf definition, as well as a set of actions related to the object. See objects.proto and  actions.proto for the actual definitions.</p> <p>Each object has an increasing numeric type ID starting from 0. At this moment, Olympia supports the following objects with their corresponding ID:</p> Object Type ID Catalog 0 Namespace 1 Table 2 View 3 Distributed Transaction 4"},{"location":"format/#tree-key-encoding","title":"Tree Key Encoding","text":"<p>There are 2 types of keys in the Olympia b-tree: system internal keys and object keys.</p>"},{"location":"format/#system-internal-keys","title":"System Internal Keys","text":"<p>System internal keys do not participate in the Olympia tree key sorting algorithm and just provide metadata information about the specific node. Here is a list of them:</p> Key Name Key Root Node Only Description Catalog Definition catalog_def Yes The catalog definition file pointer Previous Root Node previous_root Yes The pointer to the last version of the root node Rollback Root Node rollback_from_root Yes The pointer to the root node that was rolled back from, if the root node is created during a rollback Creation Timestamp created_at_millis The millisecond epoch timestamp that a node is created Number of Keys n_keys The number of rows that a node has"},{"location":"format/#object-key","title":"Object Key","text":"<p>The object key is a UTF-8 string that uniquely identifies the object and also allows sorting it in a lexicographical order that resembles the object hierarchy in a catalog.</p>"},{"location":"format/#object-name-encoding","title":"Object Name Encoding","text":"<p>The object name has maximum size in bytes defined in the catalog definition file, with one configuration for each type of object.</p> <p>The following UTF-8 characters are not permitted in an object name:</p> <ul> <li>any control characters (hex value 00 to 1F)</li> <li>the space character (hex value 20)</li> <li>the DEL character (hex value 7F)</li> </ul> <p>When used in an object key, the object name is right-padded with space up to the maximum size (excluding the initial byte). The maximum size of each object is defined in the catalog definition file.</p> <p>For example, a namespace <code>default</code> under catalog definition <code>namespace_name_max_size_bytes=8</code> will have an encoded object name<code>[space]default[space]</code>.</p>"},{"location":"format/#object-type-id-encoding","title":"Object Type ID Encoding","text":"<p>When used in the object key, the object type ID is encoded to a 4 character base64 string that uses the following encoding:</p> <ul> <li>Uppercase letters: A\u2013Z, with indices 0\u201325</li> <li>Lowercase letters: a\u2013z, with indices 26\u201351</li> <li>Digits: 0\u20139, with indices 52\u201361</li> <li>Special symbols: <code>+</code> and <code>-</code>, with indices 62\u201363</li> <li>Right padding character <code>=</code> if there are fewer than 4 characters after encoding</li> </ul> <p>For example, object type ID <code>4</code> is encoded to <code>E===</code>.</p>"},{"location":"format/#object-key-format","title":"Object Key Format","text":"<p>The object key format combines the encoded object key ID and encoded object name above to form a unique key for each type of object. See the table below for the format for each type of object:  (contents in <code>&lt;&gt;</code> should be substituted, space character is expressed as <code>[space]</code> for clarity)</p> Object Type Object Key Format Example Catalog N/A, use the catalog definition key Namespace <code>B===&lt;encoded namespace name&gt;</code> <code>B===default[space]</code> Table <code>C===&lt;encoded namespace name&gt;&lt;encoded table name&gt;</code> <code>C===default[space]table[space][space][space]</code> View <code>D===&lt;encoded namespace name&gt;&lt;encoded view name&gt;</code> <code>D===default[space]view[space][space][space][space]</code> Distributed Transaction N/A, distributed transaction is not persisted in catalog"},{"location":"format/#files","title":"Files","text":"<p>Here are the different types of files.</p>"},{"location":"format/#node-file","title":"Node File","text":"<p>To persist the whole tree on storage, each pivot table is stored as a separated file that we call a Node File. However, before storing the pivot table, it stores the system internal keys relevant to the node. Because the pivot table must begin with a row of key and value both being <code>NULL</code>, It is expected that a reader first read up to the first row of the pivot table, and read N keys of the pivot table based on the \"Number of Keys\" system internal key.</p> <p>Node files are stored under <code>node</code> folder within the catalog prefix, each node file is in Apache Arrow IPC format with file name in the form of <code>&lt;random uuid4&gt;.arrow</code>.</p>"},{"location":"format/#root-node-file","title":"Root Node File","text":"<p>Root node file is a special kind of node file.</p> <p>It also stores a list of actions performed in the last transaction after the pivot table. For these rows, the <code>key</code> column stores the object that the action is performed on.  The <code>value</code> column stores the action definition.</p> <p>Root node files are stored in the <code>vn</code> (version) folder. Each root node file is stored as the reversed binary value of the version number. For example, version 100 is stored at <code>vn/00100110000000000000000000000000</code>.</p>"},{"location":"format/#object-definition-file","title":"Object Definition File","text":"<p>Object definition files store the serialized protobuf binary for the specific object.</p> <p>These files are stored in the <code>def</code> folder, in the form of prefix <code>{object-type}/{uuid4}-{object-identifier}.binpb</code>. For example, a table <code>t1</code> in namespace <code>ns1</code> and UUID <code>6fcb514b-b878-4c9d-95b7-8dc3a7ce6fd8</code> would give a path <code>table/6fcb514b-b878-4c9d-95b7-8dc3a7ce6fd8-ns1-t1.binpb</code>, to produce the final object definition file path. For catalog, because thee is not an object identifier, files will be in the form of <code>catalog/{uuid4}.binpb</code>.</p>"},{"location":"format/#latest-version-file","title":"Latest Version File","text":"<p>The latest version file is stored at <code>vn/latest</code>. This is an optional text file that records the latest version of the node file, The file contains a number that marks the presumably latest version of the tree root node, such as <code>100</code>.</p>"},{"location":"format/#oldest-version-file","title":"Oldest Version File","text":"<p>The oldest version file is stored at <code>vn/oldest</code>. This is an optional text file marks the guaranteed oldest version of the tree root node, such as <code>100</code>.</p>"},{"location":"format/#transaction","title":"Transaction","text":""},{"location":"format/#storage-requirement","title":"Storage Requirement","text":"<p>A storage used by Olympia must support the following basic operations:</p> <ul> <li>Read a file to a given location</li> <li>Write a file to a given location</li> <li>Delete a file at a given location</li> <li>Check if a file exists at a given location</li> <li>List files sharing the same prefix</li> </ul> <p>In addition, a storage used by Olympia must support mutual exclusion of file creation. This means only one writer wins if there are multiple writers trying to write to the same new file. This is the key feature that Olympia relies on for enforcing ACID semantics during the commit process.</p> <p>This feature is widely available in most storage systems, for examples:</p> <ul> <li>On Linux File System through O_EXCL</li> <li>On Hadoop Distributed File System through atomic rename</li> <li>On Amazon S3 through IF-NONE-MATCH</li> <li>On Google Cloud Storage through IF-NONE-MATCH</li> <li>On Azure Data Lake Storage through IF-NONE-MATCH</li> </ul> <p>We can also treat key-value stores as a file system, where the key records the file path and value stores the file content bytes. This further enables the usage of systems like:</p> <ul> <li>On Amazon DynamoDB through conditional PutItem</li> <li>On Redis/Valkey through SET NX</li> </ul>"},{"location":"format/#begin-a-transaction","title":"Begin a transaction","text":"<p>A transaction, either for read or write or both, will always begin with identifying the version of the Olympia tree to look into. This version is determined by reading the latest and oldest version files. If the latest version file exists and is larger than the oldest version file or if the oldest version file does not exist,  we start to find the latest version at the version indicated by the file.  Otherwise, we start from the version described by the oldest version file, or 0 if the oldest version file does not exist. With that, we consecutively increment the version number until we find the verison <code>k</code> that returns a file not found error from storage. After this process, we treat version <code>k-1</code> as the latest version to be used.</p>"},{"location":"format/#commit-a-transaction","title":"Commit a transaction","text":""},{"location":"format/#storage-atomic-commit","title":"Storage Atomic Commit","text":"<p>When committing a transaction, the writer will first write all non-root node files in parallel, and then write the new root node file at the new version location atomically. If this write is successful, the transaction is considered succeeded, and the writer will perform a best-effort write of the latest version file. If this write is not successful, the transaction commit step has failed at the storage layer. Additional catalog commit conflict resolution is required to determine the proper action.</p>"},{"location":"format/#catalog-commit-conflict-resolution","title":"Catalog Commit Conflict Resolution","text":"<p>When a commit fails at storage level, catalog will examine all the actions performed by inspecting the list of actions stored in the latest root node, and reconcile with the current list of actions to see if the commit could still succeed. If the commit could still succeed, the writer should update the commit to be performed against the latest root node and redo the storage atomic commit. Otherwise, the commit process should abort and report failure.</p>"},{"location":"format/#distribute-a-transaction","title":"Distribute a transaction","text":"<p>A transaction can be distributed by creating a distributed transaction object. These objects are stored in the <code>dtxn</code> folder with name <code>{transaction-id}.binpb</code>. The transaction can be resumed in another process by loading the specific distributed transaction object definition.</p>"},{"location":"format/#catalog-versioning-semantics","title":"Catalog Versioning Semantics","text":"<p>Here are the semantics to follow for catalog versioning related features of Olympia:</p>"},{"location":"format/#time-travel","title":"Time Travel","text":"<p>Because the Olympia tree node is versioned, time travel against the tree root, i.e. time travel against the entire Olympia catalog, is possible.</p> <p>The timestamp-based time travel can be achieved by continuously tracing the previous root node key to older root nodes, and check the creation timestamp key until the right root node for time travel is found.</p> <p>For version-based time travel, when the system version is a numeric value, it should map to the version of the tree root node. The root node of the specific version can directly be found based on the root node file name. When the system version is a string that does not resemble a numeric value, it should map to a possible exported snapshot.</p>"},{"location":"format/#catalog-rollback","title":"Catalog Rollback","text":"<p>Olympia uses the roll forward technique for rolling back any committed version. If the current latest root node version is <code>v</code>, and a user would like to roll back to version <code>v-1</code>, Rollback is performed by committing a new root node with version <code>v+1</code> which is most identical to the root node file <code>v-1</code>, with the difference that the root node <code>v</code> should be recorded as the rollback root node key.</p>"},{"location":"format/#snapshot-export","title":"Snapshot Export","text":"<p>A snapshot export for an Olympia catalog means to export a specific version of the Olympia tree root node, and all the files that are reachable through that root node. Every time an export is created, the catalog definition should be updated to record the name of the export and the root node file that the export is at.</p> <p>There are many types of export that can be achieved, because the export process can decide to stop replication at any level of the tree and call it an export. At one extreme, a process can replicate any reachable files starting at the root node. We call this a Full Export. On the other side, a process can simply replicate the specific version of tree root node, and all other files reachable from the root node are not replicated. We call this a Minimal Export. We call any export that is in between a Partial Export.</p> <p>Any file that is referenced by both the exported snapshot and the source catalog might be removed by the catalog version expiration process. With a full snapshot export, all files are replicated and dereferenced from the source catalog. With a partial or minimal export, additional retention policy settings are required to make sure the version expiration process still keep those files available for a certain amount of time.</p>"},{"location":"iceberg/","title":"Iceberg Catalog Integration","text":"<p>Olympia provides an implementation of the pluggable Java <code>Catalog</code> API standard in Apache Iceberg  with class path <code>org.format.olympia.iceberg.OlympiaIcebergCatalog</code>.</p> <p>See related Iceberg documentation for how to use it standalone or with various query engines like Apache Spark, Apache Flink, and Apache Hive.</p>"},{"location":"iceberg/#catalog-properties","title":"Catalog Properties","text":"<p>The Olympia Iceberg catalog exposes the following catalog properties:</p> Property Name Description Required? Default warehouse The Iceberg catalog warehouse location, should be set to the root location for the catalog storage Yes storage.type Type of storage. If not set, the type is inferred from the root URI scheme. No storage.ops.&lt;key&gt; Any property configuration for a specific type of storage operation. No system.ns-name Name of the system namespace No sys dtxn.parent-ns-name Name of the parent namespace for all distributed transactions. This parent namespace is within the system namespace and hold all distributed transaction namespaces No dtxns dtxn.ns-prefix The prefix for a namespace to represent a distributed transaction No dtxn_ <p>For example, a user can initialize an Olympia Iceberg catalog Java instance with:</p> <pre><code>import io.Olympia.iceberg.OlympiaIcebergCatalog;\nimport io.Olympia.relocated.com.google.common.collect.ImmutableMap;\nimport org.apache.iceberg.catalog.Catalog;\nimport org.apache.iceberg.catalog.CatalogProperties;\nimport org.apache.iceberg.catalog.SupportsNamespaces;\n\nCatalog catalog = new OlympiaIcebergCatalog();\ncatalog.initialize(\n        ImmutableMap.of(\n                CatalogProperties.WAREHOUSE_LOCATION, // \"warehouse\"\n                \"s3://my-bucket\"));\n\nSupportsNamespaces nsCatalog = (SupportsNamespace) catalog;\n</code></pre>"},{"location":"iceberg/#operation-behavior","title":"Operation Behavior","text":"<p>When using Olympia through Iceberg catalog,  all the operations will first begin a transaction and then perform the operation. If the operation modifies the object, it will commit the transaction to the catalog.</p> <p>When using Iceberg transactions to perform multiple operations, Olympia will begin a transaction, perform all the operations and then commit the transaction to the catalog. For example:</p> <pre><code>import org.apache.iceberg.catalog.TableIdentifier;\nimport org.apache.iceberg.types.Types;\n\nTable table = catalog.loadTable(TableIdentifier.of(\"ns1\", \"t1\"));\nTransaction txn = table.newTransaction();\n\ntxn.updateSchema()\n    .addColumn(\"region\", Types.StringType.get())\n    .commit();\n\ntxn.updateSpec()\n    .addField(\"region\")\n    .commit();\n\ntxn.commitTransaction();\n</code></pre> <p>In this sequence, an Olympia transaction will hold the schema and partition spec update, and commit both changes to catalog in a single transaction.</p>"},{"location":"iceberg/#using-system-namespace","title":"Using System Namespace","text":"<p>The system namespace is a special namespace with name determined by <code>system.ns-name</code> that exists if an Olympia catalog is initialized at the <code>warehouse</code> location. It contains information about the distributed transactions that are available to use in the catalog.</p>"},{"location":"iceberg/#create-a-new-olympia-catalog","title":"Create a new Olympia catalog","text":"<p>If there is no Olympia catalog at the configured <code>warehouse</code> location, the system namespace will not exist. The act of creating this system namespace represents creating the catalog. At creation time, catalog definition fields can be supplied through the namespace properties.</p> <p>For example:</p> <pre><code>import org.apache.iceberg.Namespace;\n\nnsCatalog.createNamespace(\n        Namespace.of(\"sys\"), \n        ImmutableMap.of(\"namespace_name_max_size_bytes\", \"256\"));\n</code></pre>"},{"location":"iceberg/#using-distributed-transaction","title":"Using Distributed Transaction","text":"<p>You can use the Olympia transaction semantics through Iceberg multi-level namespace.</p>"},{"location":"iceberg/#distributed-transactions-namespace","title":"Distributed transactions namespace","text":"<p>Under the system namespace, there is always a namespace with name determined by <code>dtxn.parent-ns-name</code>. This is the parent namespace that holds all the distributed transactions. Each distributed transaction is represented by a namespace with prefix determined by <code>dtxn.ns-prefix</code>, followed by the transaction ID.</p> <p>For example, if there are 2 distributed transactions with IDs <code>123</code> and <code>456</code>, you should see the following namespace hierarchy:</p> <pre><code>\u2514\u2500\u2500 sys\n    \u2514\u2500\u2500 dtxns\n        \u251c\u2500\u2500 dtxn_123\n        \u2514\u2500\u2500 dtxn_456\n</code></pre>"},{"location":"iceberg/#list-all-transactions","title":"List all transactions","text":"<p>Users can list all the distributed transactions currently in the catalog by doing a namespace listing of the parent namespace of all distributed transactions:</p> <pre><code>nsCatalog.listNamespace(Namespace.of(\"sys\", \"dtxns\"));\n</code></pre>"},{"location":"iceberg/#begin-a-transaction","title":"Begin a transaction","text":"<p>If you create a namespace with a prefix matching the <code>dtxn.ns-prefix</code>, and the namespace is within the system namespace, and also under the parent namespace <code>dtx.parent-ns-prefix</code>, then it is considered as beginning a distributed transaction.</p> <p>The namespace properties are used to provide runtime override options for the transaction. The following options are supported:</p> Option Name Description isolation-level The isolation level of this transaction ttl-millis The duration for which a transaction is valid in milliseconds <p>The act of creating such a namespace means to create a distributed transaction that is persisted in the catalog. For example, consider a user creating a transaction with ID <code>123</code> with isolation level as <code>SERIALIZABLE</code>:</p> <pre><code>nsCatalog.createNamespace(\n        Namespace.of(\"sys\", \"dtxns\", \"dtxn_123\"), \n        ImmutableMap.of(\"isolation-level\", \"serializable\"));\n</code></pre>"},{"location":"iceberg/#using-the-transaction","title":"Using the transaction","text":"<p>After creation, a user can access the specific isolated version of the catalog under the namespace. For example, consider an Olympia catalog with namespace <code>ns1</code> and table <code>t1</code>, then the user should see a namespace <code>sys.dtxns.dtxn_123.ns1</code> and a table <code>sys.dtxns.dtxn_123.ns1.t1</code> which the user can read and write to:</p> <pre><code>assertThat(catalog.listNamespaces(Namespace.of(\"sys\", \"dtxns\", \"dtxn_123\")))\n        .containsExactly(Namespace.of(\"sys\", \"dtxns\", \"dtxn_123\", \"ns1\"));\n\nassertThat(catalog.listTables(Namespace.of(\"sys\", \"dtxns\", \"dtxn_123\", \"ns1\")))\n        .containsExactly(TableIdentifier.of(\"sys\", \"dtxns\", \"dtxn_123\", \"ns1\", \"t1\"));\n</code></pre>"},{"location":"iceberg/#commit-a-transaction","title":"Commit a transaction","text":"<p>In order to commit this transaction, set the namesapce property <code>commit</code> to <code>true</code>:</p> <pre><code>nsCatalog.setProperties(\n        Namespace.of(\"sys\", \"dtxns\", \"dtxn_123\"), \n        ImmutbaleMap.of(\"commit\", \"true\"));\n</code></pre>"},{"location":"iceberg/#rollback-a-transaction","title":"Rollback a transaction","text":"<p>In order to rollback a transaction, perform a drop namespace:</p> <pre><code>nsCatalog.dropNamespace(\n        Namespace.of(\"sys\", \"dtxns\", \"dtxn_123\"));\n</code></pre>"},{"location":"iceberg/#iceberg-rest-catalog","title":"Iceberg REST Catalog","text":"<p>Olympia provides the ability to build an Iceberg REST Catalog (IRC) server following the IRC open catalog standard.</p> <p>The Olympia-backed IRC offers the same operation behavior as the Iceberg catalog integration for using system namespace and distributed transaction.</p>"},{"location":"iceberg/#apache-gravitino-irc-server","title":"Apache Gravitino IRC Server","text":"<p>The easiest way to start an Olympia-backed IRC server is to use the Apache Gravitino IRC Server. You can run the Gravitino Iceberg REST server integrated with Olympia backend in two ways.</p>"},{"location":"iceberg/#using-the-prebuilt-docker-image-recommended","title":"Using the Prebuilt Docker Image (Recommended)","text":"<p>Pull the docker image from official Olympia docker account <pre><code>docker pull olympiaformat/olympia-gravitino-irc:latest\n</code></pre></p> <p>Run the Gravitino IRC Server container with port mapping <pre><code>docker run -d -p 9001:9001 --name olympia-gravitino-irc olympiaformat/olympia-gravitino-irc\n</code></pre></p>"},{"location":"iceberg/#using-apache-gravitino-installation-manual-setup","title":"Using Apache Gravitino Installation (Manual Setup)","text":"<p>Follow the Apache Gravitino instructions for downloading and installing the Gravitino software. After the standard installation process, add the <code>olympia-core-0.0.1.jar</code> and <code>olympia-s3-0.0.1.jar</code> to your Java classpath or copy those jars into Gravitino\u2019s <code>lib/</code> directory .</p>"},{"location":"iceberg/#configuration","title":"Configuration","text":"<p>Update <code>gravitino-iceberg-rest-server.conf</code> with the following configuration:</p> Configuration Item Description Value gravitino.iceberg-rest.catalog-backend The Catalog backend of the Gravitino Iceberg REST catalog service custom gravitino.iceberg-rest.catalog-backend-impl The Catalog backend implementation of the Gravitino Iceberg REST catalog service. io.Olympia.iceberg.OlympiaIcebergCatalog gravitino.iceberg-rest.catalog-backend-name The catalog backend name passed to underlying Iceberg catalog backend. any name you like, e.g. <code>olympia</code> gravitino.iceberg-rest.uri Iceberg REST catalog server address For local development, use <code>http://127.0.0.1:9001</code> gravitino.iceberg-rest.warehouse Olympia catalog storage root location Any file path. Ex: <code>/tmp/olympia</code> gravitino.iceberg-rest.&lt;key&gt; Any other catalog properties"},{"location":"iceberg/#running-the-server","title":"Running the server","text":"<p>To start the Gravitino Iceberg REST server <pre><code>./bin/gravitino-iceberg-rest-server.sh start\n</code></pre></p> <p>To stop the Gravitino Iceberg REST server <pre><code>./bin/gravitino-iceberg-rest-server.sh stop\n</code></pre></p> <p>Follow the Apache Gravitino instructions for more detailed instructions on starting the IRC server and exploring the namespaces, tables and distributed transactions in the catalog.</p>"},{"location":"iceberg/#examples","title":"Examples","text":"<p>List all IRC configurations:</p> <pre><code>curl -X GET \"http://127.0.0.1:9001/iceberg/v1/config\"\n</code></pre> <p>Create catalog:</p> <pre><code>curl -X POST \"http://127.0.0.1:9001/iceberg/v1/namespaces\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"namespace\": [\"sys\"],\n           \"properties\": {}\n         }'\n</code></pre> <p>List namespaces:</p> <pre><code>curl -X GET \"http://127.0.0.1:9001/iceberg/v1/namespaces\"\n</code></pre>"},{"location":"spark/","title":"Spark Integration","text":"<p>Olympia can be used through the Spark Iceberg connector by leveraging the Olympia Iceberg Catalog or Olympia Iceberg REST Catalog integrations.</p>"},{"location":"spark/#configuration","title":"Configuration","text":""},{"location":"spark/#olympia-iceberg-catalog","title":"Olympia Iceberg Catalog","text":"<p>To configure an Iceberg catalog with Olympia in Spark, you should:</p> <ul> <li>Add Olympia Spark Iceberg runtime package to the Spark classpath</li> <li>Use the Spark Iceberg connector configuration for custom catalog.</li> </ul> <p>For example, to start a Spark shell session with a Olympia Iceberg catalog named <code>demo</code>:</p> <pre><code>spark-shell \\\n  --jars iceberg-spark-runtime-3.5_2.12.jar,olympia-spark-iceberg-runtime-3.5_2.12.jar \\\n  --conf spark.sql.extensions=org.apache.spark.iceberg.extensions.IcebergSparkSessionExtensions,\n                              org.format.olympia.spark.extensions.OlympiaSparkExtensions \\\n  --conf spark.sql.catalog.demo=org.apache.spark.iceberg.SparkCatalog \\\n  --conf spark.sql.catalog.demo.catalog-impl=org.format.olympia.iceberg.OlympiaIcebergCatalog \\\n  --conf spark.sql.catalog.demo.warehouse=s3://my-bucket\n</code></pre>"},{"location":"spark/#olympia-iceberg-rest-catalog","title":"Olympia Iceberg REST Catalog","text":"<p>To configure an Iceberg REST catalog with Olympia in Spark, you should:</p> <ul> <li>Start your Olympia IRC server</li> <li>Add Olympia Spark Iceberg runtime package to the Spark classpath</li> <li>Use the Spark Iceberg connector configuration for IRC.</li> </ul> <p>For example, to start a Spark shell session with a Olympia IRC catalog named <code>demo</code> that is running at <code>http://localhost:8000</code>:</p> <pre><code>spark-shell \\\n  --jars iceberg-spark-runtime-3.5_2.12.jar \\\n  --conf spark.sql.extensions=org.apache.spark.iceberg.extensions.IcebergSparkSessionExtensions \\\n  --conf spark.sql.catalog.demo=org.apache.spark.iceberg.SparkCatalog \\\n  --conf spark.sql.catalog.demo.type=rest \\\n  --conf spark.sql.catalog.demo.uri=http://localhost:8000\n</code></pre> <p>Failure</p> <p>The IRC integration cannot work with the Olympia Spark SQL extensions at this moment  because of missing transaction features in IRC. It has no notion of a transaction start, and cannot track a transaction across operations.</p>"},{"location":"spark/#using-sql-extensions","title":"Using SQL Extensions","text":"<p>Olympia provides the following Spark SQL extensions for its Spark connector:</p>"},{"location":"spark/#begin-transaction","title":"BEGIN TRANSACTION","text":"<p>Begin a transaction.</p> <pre><code>BEGIN [ TRANSACTION ]\n</code></pre>"},{"location":"spark/#commit-transaction","title":"COMMIT TRANSACTION","text":"<p>Commit a transaction. This command can only be used after executing a <code>BEGIN TRANSACTION</code></p> <pre><code>COMMIT [ TRANSACTION ]\n</code></pre>"},{"location":"spark/#rollback-transaction","title":"ROLLBACK TRANSACTION","text":"<p>Rollback a transaction. This command can only be used after executing a <code>BEGIN TRANSACTION</code></p> <pre><code>ROLLBACK [ TRANSACTION ]\n</code></pre>"},{"location":"spark/#using-system-namespace","title":"Using System Namespace","text":"<p>The Olympia Spark Iceberg connector offers the same system namespace support as the Iceberg catalog integration to perform operations like create catalog and list distributed transactions. See Using System Namespace in Iceberg Catalog for more details.</p> <p>For examples:</p> <pre><code>-- create catalog\nCREATE DATABASE sys;\n\nSHOW DATABASES IN sys\n---------\n|name   |\n---------    \n|dtxns  |\n\n-- list distributed transactions in the catalog\nSHOW DATABASES IN sys.dtxns\n------------\n|name      |\n------------    \n|dtxn_123  |\n|dtxn_456  |\n</code></pre>"},{"location":"spark/#using-distributed-transaction","title":"Using Distributed Transaction","text":"<p>The Spark Iceberg connector for Olympia offers the same distributed transaction support as the Iceberg catalog integration using multi-level namespace. See Using Distributed Transaction in Iceberg Catalog for more details.</p> <p>For examples:</p> <pre><code>-- create a transaction with ID 1234\nCREATE DATABASE system.dtxns.dtxn_1234\n       WITH DBPROPERTIES ('isolation-level'='serializable')\n\n-- list tables in transaction of ID 1234 under namespace ns1\nSHOW TABLES IN sys.dtxns.dtxn_1234.ns1;\n------\n|name|\n------     \n|t1  |\n\nSELECT * FROM sys.dtxns.dtxn_1234.ns1.t1;\n-----------\n|id |data |\n-----------\n|1  |abc  |\n|2  |def  |\n\nINSERT INTO sys.dtxns.dtxn_1234.ns1.t1 VALUES (3, 'ghi');\n\n-- commit transaction with ID 1234\nALTER DATABASE sys.dtxns.dtxn_1234\n      SET DBPROPERTIES ('commit' = 'true');\n</code></pre>"}]}